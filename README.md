# Wig Try-On iOS ğŸ­ğŸ“±

Native iOS app for real-time virtual wig try-on using ARKit Face Tracking.

## Features

- **ARKit Face Tracking** â€” Apple's high-accuracy face mesh (1220 vertices)
- **TrueDepth Camera** â€” Real depth data for accurate 3D positioning
- **3D Wig Models** â€” SceneKit rendering with realistic lighting
- **Real-time Preview** â€” 60 FPS smooth experience
- **Photo Capture** â€” Save try-on photos to Camera Roll

## Requirements

- **iPhone X or later** (requires TrueDepth camera)
- **iOS 15.0+**
- **Xcode 15.0+**

## Setup

1. Open `WigTryOn.xcodeproj` in Xcode
2. Select your development team in Signing & Capabilities
3. Connect your iPhone
4. Build and run (âŒ˜R)

## Project Structure

```
WigTryOn/
â”œâ”€â”€ WigTryOnApp.swift           # App entry point
â”œâ”€â”€ ContentView.swift           # Main SwiftUI view
â”œâ”€â”€ Views/
â”‚   â”œâ”€â”€ ARViewContainer.swift   # ARKit view wrapper
â”‚   â”œâ”€â”€ WigSelectorView.swift   # Wig selection UI
â”‚   â””â”€â”€ ControlsView.swift      # Adjustment controls
â”œâ”€â”€ Models/
â”‚   â”œâ”€â”€ Wig.swift               # Wig data model
â”‚   â””â”€â”€ WigManager.swift        # Wig loading/management
â”œâ”€â”€ Services/
â”‚   â”œâ”€â”€ ARFaceTracker.swift     # ARKit face tracking
â”‚   â””â”€â”€ WigRenderer.swift       # 3D wig rendering
â”œâ”€â”€ Resources/
â”‚   â””â”€â”€ Wigs/                   # 3D wig models (.usdz, .scn)
â””â”€â”€ Info.plist
```

## How It Works

```
TrueDepth Camera
       â†“
ARKit Face Tracking
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Face Mesh (1220 pts)â”‚
â”‚ + Blend Shapes (52) â”‚
â”‚ + Head Transform    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
   3D Wig Positioning
           â†“
   SceneKit Rendering
           â†“
      AR Preview
```

## Adding Wigs

Place 3D models in `Resources/Wigs/`:
- **Supported formats:** `.usdz`, `.scn`, `.dae`
- **Orientation:** Y-up, facing -Z
- **Scale:** Normalized to ~20cm head size

### Convert from .glb/.obj:

```bash
# Using Reality Converter (free from Apple)
# Or programmatically with Model I/O
```

## ARKit Face Tracking

The app uses ARKit's face tracking which provides:

| Feature | Description |
|---------|-------------|
| **Face Mesh** | 1220 vertices, real-time deformation |
| **Blend Shapes** | 52 facial expressions |
| **Head Pose** | Position + rotation in 3D space |
| **Eye Tracking** | Gaze direction |
| **Depth Map** | Per-pixel depth from TrueDepth |

## Controls

| Gesture | Action |
|---------|--------|
| Swipe Left/Right | Change wig |
| Pinch | Scale wig |
| Two-finger drag | Adjust position |
| Tap | Take photo |
| Long press | Reset |

## Privacy

- Camera access required (face tracking)
- Photo library access for saving (optional)
- No data leaves the device

## License

MIT License
